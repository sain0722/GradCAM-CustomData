{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-f1fc9784eb9f>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if tf.test.is_gpu_available() else \"CPU\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Dataset\n",
    "# Square1, Square2, Circle1, Circle2, Triangle1, Triangle2\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "# Fixed for Cats & Dogs color images\n",
    "CHANNELS = 3\n",
    "\n",
    "IMAGE_RESIZE = 224\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 10\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
    "STEPS_PER_EPOCH_TRAINING = 7\n",
    "STEPS_PER_EPOCH_VALIDATION = 7\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
    "BATCH_SIZE_TRAINING = 3\n",
    "BATCH_SIZE_VALIDATION = 3\n",
    "\n",
    "# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\n",
    "BATCH_SIZE_TESTING = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still not talking about our train/test data or any pre-processing.\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
    "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = 'imagenet'))\n",
    "\n",
    "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
    "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "\n",
    "# Say not to train first layer (ResNet) model as it is already trained\n",
    "# model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103 images belonging to 6 classes.\n",
      "Found 18 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = IMAGE_RESIZE\n",
    "\n",
    "# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)\n",
    "# Each of the keras.application.resnet* preprocess_input MOSTLY mean BATCH NORMALIZATION (applied on each batch) stabilize the inputs to nonlinear activation functions\n",
    "# Batch Normalization helps in faster convergence\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "\n",
    "# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n",
    "# Both train & valid folders must have NUM_CLASSES sub-folders\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "        './data/Benchmarkimage_20200821/train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_TRAINING,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "        './data/Benchmarkimage_20200821/val/',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_VALIDATION,\n",
    "        class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping & checkpointing the best model in ./working dir & restoring that as our model for prediction\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = './working/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - ETA: 0s - loss: 2.6433 - accuracy: 0.3810WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7 batches). You may need to use the repeat() function when building your dataset.\n",
      "7/7 [==============================] - 7s 976ms/step - loss: 2.6433 - accuracy: 0.3810 - val_loss: 85.5173 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 3s 369ms/step - loss: 3.1137 - accuracy: 0.2857\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 3s 473ms/step - loss: 2.2847 - accuracy: 0.3810\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 1.9756 - accuracy: 0.4286\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 2s 337ms/step - loss: 1.7677 - accuracy: 0.3810\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 3s 369ms/step - loss: 1.6364 - accuracy: 0.5789\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 2s 275ms/step - loss: 1.7308 - accuracy: 0.3684\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 3s 404ms/step - loss: 2.7075 - accuracy: 0.1579\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 3s 361ms/step - loss: 1.9520 - accuracy: 0.2105\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 3s 403ms/step - loss: 1.7207 - accuracy: 0.3684\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "#        callbacks=[cb_checkpointer, cb_early_stopper]\n",
    ")\n",
    "# model.load_weights(\"./working/best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.643294095993042,\n",
       "  3.1136507987976074,\n",
       "  2.2846925258636475,\n",
       "  1.9755979776382446,\n",
       "  1.7676609754562378,\n",
       "  1.636400818824768,\n",
       "  1.7307558059692383,\n",
       "  2.707475185394287,\n",
       "  1.9520468711853027,\n",
       "  1.7206684350967407],\n",
       " 'accuracy': [0.380952388048172,\n",
       "  0.2857142984867096,\n",
       "  0.380952388048172,\n",
       "  0.4285714328289032,\n",
       "  0.380952388048172,\n",
       "  0.5789473652839661,\n",
       "  0.3684210479259491,\n",
       "  0.15789473056793213,\n",
       "  0.21052631735801697,\n",
       "  0.3684210479259491],\n",
       " 'val_loss': [85.51728057861328],\n",
       " 'val_accuracy': [0.0]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = data_generator.flow_from_directory(\n",
    "        './data/Benchmarkimage_20200821/test/',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_TESTING,\n",
    "        class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 105ms/step - loss: 18012970.0000 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_generator,\n",
    "                        steps = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
